
ğŸš€ Mini LipReader â€“ Simplified Lip Reading Demo

è¿·ä½ å”‡è¯­è¯†åˆ«æ¨¡å‹

ğŸ“Œ Overview | é¡¹ç›®æ¦‚è¿°

EN:
Mini LipReader is a simplified, ready-to-run lip-reading demo based on the general architecture of TCN-style lip-reading models.
It does not require large datasets or model training.
Simply load a lightweight pre-trained model and run inference on a short lip-movement video.

This project is perfect for:

AI/ML beginners

Students preparing portfolio / interview demos

Anyone who wants a functional lip-reading pipeline without heavy computation

ä¸­æ–‡ï¼š
Mini LipReader æ˜¯ä¸€ä¸ªåŸºäº TCN å”‡è¯­è¯†åˆ«æ€æƒ³æ„å»ºçš„ å¯ç›´æ¥è¿è¡Œçš„è½»é‡åŒ– Demoã€‚
ä½ æ— éœ€è®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿæ— éœ€ä¸‹è½½å¤§å‹æ•°æ®é›†ï¼Œåªéœ€åŠ è½½ä¸€ä¸ªè½»é‡æ¨¡å‹å¹¶å¯¹çŸ­è§†é¢‘è¿›è¡Œæ¨ç†å³å¯ã€‚

æœ¬é¡¹ç›®éå¸¸é€‚åˆï¼š

äººå·¥æ™ºèƒ½å…¥é—¨å­¦ä¹ 

éœ€è¦åˆ¶ä½œæ±‚èŒä½œå“é›†æˆ–é¢è¯• Demo çš„åŒå­¦

å¸Œæœ›ä½“éªŒâ€œå”‡è¯­è¯†åˆ«â€å®Œæ•´æµç¨‹ä½†ä¸æƒ³æŠ˜è…¾è®­ç»ƒçš„äºº

ğŸ“ Project Structure | é¡¹ç›®ç»“æ„
LipReader-Mini/
â”‚
â”œâ”€â”€ models/
â”‚     â””â”€â”€ lipreader_tiny.pth         # Tiny pre-trained model | è½»é‡é¢„è®­ç»ƒæ¨¡å‹
â”‚
â”œâ”€â”€ sample/
â”‚     â””â”€â”€ sample_lip.mp4             # Sample input video | ç¤ºä¾‹è§†é¢‘
â”‚
â”œâ”€â”€ infer.py                         # Inference script | æ¨ç†è„šæœ¬
â”œâ”€â”€ requirements.txt                 # Environment deps | ç¯å¢ƒä¾èµ–
â””â”€â”€ README.md                        # This file | æœ¬è¯´æ˜æ–‡ä»¶

âš™ï¸ Installation | å®‰è£…ç¯å¢ƒ
1. Install dependencies | å®‰è£…ä¾èµ–
pip install -r requirements.txt

2. (Optional) Create virtual environment | å¯é€‰ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/Scripts/activate        # Windows Git Bash
# æˆ–
venv\Scripts\activate               # Windows PowerShell

â–¶ï¸ How to Run Inference | å¦‚ä½•è¿è¡Œæ¨ç†

Use the provided sample video:

EN:

python infer.py --video sample/sample_lip.mp4 --model models/lipreader_tiny.pth


ä¸­æ–‡ï¼š

ä½¿ç”¨ç¤ºä¾‹è§†é¢‘è¿è¡Œæ¨ç†ï¼š

python infer.py --video sample/sample_lip.mp4 --model models/lipreader_tiny.pth


If everything works, you will see output like:

Predicted: HELLO


è‹¥è¿è¡Œæ­£å¸¸ï¼Œä½ ä¼šçœ‹åˆ°ï¼š

Predicted: HELLO

ğŸ§  How It Works | åŸç†è¯´æ˜

EN:
The tiny model is a simplified version of lip-reading architectures commonly built using:

CNN backbone for visual feature extraction

Temporal Convolutional Network (TCN) for sequence modeling

FC output layer for classification

Pipeline steps:

Load video

Extract & preprocess frames (resize + normalize)

Stack frames into (Batch Ã— Time Ã— C Ã— H Ã— W)

Feed into the model

Output predicted class

ä¸­æ–‡ï¼š
è¯¥è½»é‡æ¨¡å‹æ˜¯å¸¸è§å”‡è¯­è¯†åˆ«ç»“æ„çš„ç®€åŒ–ç‰ˆï¼Œé€šå¸¸ç”±ä»¥ä¸‹éƒ¨åˆ†ç»„æˆï¼š

CNN ä¸»å¹²æå–è§†è§‰ç‰¹å¾

æ—¶é—´å·ç§¯ç½‘ç»œï¼ˆTCNï¼‰å»ºæ¨¡æ—¶åºä¿¡æ¯

å…¨è¿æ¥å±‚è¿›è¡Œåˆ†ç±»è¾“å‡º

æ•´ä¸ªæµæ°´çº¿åŒ…æ‹¬ï¼š

åŠ è½½è§†é¢‘

æå–å¹¶é¢„å¤„ç†å¸§ï¼ˆç¼©æ”¾ + å½’ä¸€åŒ–ï¼‰

å°†æ‰€æœ‰å¸§å †å ä¸ºæ¨¡å‹å¯è¯†åˆ«çš„è¾“å…¥æ ¼å¼

è¾“å…¥æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­

è¾“å‡ºé¢„æµ‹ç±»åˆ«# LipReader-Mini
